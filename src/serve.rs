// ###################################
// ->   SERVE
// ###################################
use crate::app::App;
use crate::fallback::static_file_and_err_handler;

use axum::{body::Body, middleware, Router};
use http::{HeaderName, Request, Response};
use leptos::LeptosOptions;
use leptos_axum::LeptosRoutes;
use leptos_router::RouteListing;
use std::time::Duration;
use tokio::net::TcpListener;
use tower::ServiceBuilder;
use tower_http::{
    classify::ServerErrorsFailureClass,
    request_id::{MakeRequestUuid, PropagateRequestIdLayer, SetRequestIdLayer},
    trace::TraceLayer,
};
use tracing::Span;

const REQUEST_ID_HEADER: &str = "x-request-id";

/// SERVE
/// The core async function returning a future that will serve this application.
///
/// Accepts a "TcpListener", `routes` generated by Leptos and the `state`(currently only `LeptosOptions`) and creates an App Router.
/// It sets up a TraceLayer that provides console logging.
/// It returns a `Result` containing a `Serve` future. Needs to be awaited like so:
/// ```ignore
/// maj_leptos::serve(listener, routes, leptos_options).await?;
/// ```
pub async fn serve(
    listener: TcpListener,
    routes: Vec<RouteListing>,
    state: LeptosOptions,
) -> Result<(), Box<dyn std::error::Error>> {
    let x_request_id = HeaderName::from_static(REQUEST_ID_HEADER);

    let trace_layer = TraceLayer::new_for_http()
        .make_span_with(|req: &Request<Body>| {
            let uuid = req
                .headers()
                .get(REQUEST_ID_HEADER)
                .map(|uuid| uuid.to_str().unwrap_or("").to_string());

            tracing::info_span!("req", id = uuid)
        })
        .on_response(|res: &Response<Body>, latency: Duration, _s: &Span| {
            let st_code = res.status();
            tracing::info!("END in: {:?} STATUS: {st_code}", latency)
        })
        .on_request(|req: &Request<Body>, _s: &Span| {
            tracing::info!("START: {} @ {}", req.method(), req.uri().path(),)
        })
        .on_failure(
            |err: ServerErrorsFailureClass, latency: Duration, _s: &Span| {
                tracing::error!("ERROR: {err:?} â€” latency: {:?}", latency)
            },
        );

    // build our application with a route
    let app = Router::new()
        .leptos_routes(&state, routes, App)
        .route("/health-check", axum::routing::get(health))
        .layer(
            ServiceBuilder::new()
                // Set the compression layer
                .layer(tower_http::compression::CompressionLayer::new())
                // Set UUID per request
                .layer(SetRequestIdLayer::new(
                    x_request_id.clone(),
                    MakeRequestUuid,
                ))
                .layer(trace_layer)
                // Propagate UUID to response, keep it last so it processes the response first!
                .layer(PropagateRequestIdLayer::new(x_request_id)),
        )
        .fallback(static_file_and_err_handler)
        .layer(middleware::map_response(midware::add_cache_control_header))
        .with_state(state);

    axum::serve(listener, app).await?;

    Ok(())
}

async fn health() -> axum::http::StatusCode {
    http::StatusCode::OK
}

mod midware {
    use axum::response::Response;

    pub async fn add_cache_control_header(mut res: Response) -> Response {
        tracing::debug!("Adding cache control header");
        if cfg!(debug_assertions) {
            res.headers_mut().insert(
                "Cache-Control",
                "no-store, no-cache, must-revalidate, proxy-revalidate"
                    .parse()
                    .unwrap(),
            );
        } else {
            res.headers_mut().insert(
                "Cache-Control",
                "max-age=3600, must-revalidate".parse().unwrap(),
            );
        }
        res
    }
}
